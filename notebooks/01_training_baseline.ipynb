{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Chronos-2 Training & Benchmarking\n",
                "\n",
                "This notebook establishes a training baseline for Chronos-2 using synthetic data and evaluates on Monash benchmarks."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Setup & Configuration"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Clone Repository\n",
                "!git clone https://github.com/emanueleromito/voyagers-forecasting.git\n",
                "%cd voyagers-forecasting\n",
                "\n",
                "# Create checkpoint directory\n",
                "import os\n",
                "CHECKPOINT_DIR = './checkpoints'\n",
                "os.makedirs(CHECKPOINT_DIR, exist_ok=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install dependencies\n",
                "!pip install -e .[dev]\n",
                "!pip install gluonts transformers accelerate typer typer-config rich wandb\n",
                "\n",
                "# Fix SymPy compatibility issue with PyTorch\n",
                "!pip install --upgrade sympy"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"Downloading synthetic dataset from Hugging Face Hub...\")\n",
                "HF_REPO_ID = \"voyagersnlppolito/model-data\"\n",
                "HF_TOKEN = userdata.get('HF_TOKEN')\n",
                "\n",
                "dataset_path = hf_hub_download(\n",
                "    repo_id=HF_REPO_ID,\n",
                "    filename=\"synthetic_dataset.pt\",\n",
                "    repo_type=\"dataset\",\n",
                "    token=HF_TOKEN\n",
                ")\n",
                "print(f\"Dataset downloaded to {dataset_path}\")\n",
                "\n",
                "full_dataset = torch.load(dataset_path)\n",
                "print(f\"Loaded {len(full_dataset)} samples.\")\n",
                "\n",
                "# Split into train/val\n",
                "train_size = int(0.9 * len(full_dataset))\n",
                "val_size = len(full_dataset) - train_size\n",
                "train_data, val_data = torch.utils.data.random_split(full_dataset, [train_size, val_size])\n",
                "\n",
                "# Convert to lists for Chronos2Dataset\n",
                "train_data = list(train_data)\n",
                "val_data = list(val_data)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1.1 Configuration & Hyperparameters\n",
                "\n",
                "Centralized configuration for data generation, model architecture, and training."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- Reproducibility ---\n",
                "SEED = 42\n",
                "\n",
                "# --- Data Generation (KernelSynth) ---\n",
                "DATA_LENGTH = 4096\n",
                "NUM_SAMPLES = 1000\n",
                "MAX_KERNELS = 5\n",
                "PERIODICITIES = [24, 48, 96, 168, 336, 720, 1440, 8760, 17520]\n",
                "LENGTH_SCALES = [0.1, 1.0, 10.0]\n",
                "DATA_PATH = Path(\"kernelsynth-data-paper.arrow\")\n",
                "\n",
                "# --- Model Configuration ---\n",
                "CONTEXT_LENGTH = 2048\n",
                "PREDICTION_LENGTH = 64\n",
                "PATCH_SIZE = 8\n",
                "D_MODEL = 256\n",
                "D_KV = 32\n",
                "D_FF = 1024\n",
                "NUM_LAYERS = 4\n",
                "NUM_HEADS = 4\n",
                "DROPOUT_RATE = 0.1\n",
                "VOCAB_SIZE = 2\n",
                "QUANTILES = [0.01, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95, 0.99]\n",
                "\n",
                "# --- Training Configuration ---\n",
                "BATCH_SIZE = 32\n",
                "LEARNING_RATE = 1e-3\n",
                "MAX_STEPS = 200000\n",
                "SAVE_STEPS = 100000\n",
                "LOGGING_STEPS = 10000\n",
                "WARMUP_RATIO = 0.0\n",
                "RUN_NAME = \"chronos2-baseline\""
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1.2 Reproducibility Setup"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def set_seed(seed: int = 42):\n",
                "    random.seed(seed)\n",
                "    np.random.seed(seed)\n",
                "    torch.manual_seed(seed)\n",
                "    torch.cuda.manual_seed_all(seed)\n",
                "    transformers.set_seed(seed)\n",
                "    \n",
                "    # Ensure deterministic behavior in PyTorch (may impact performance)\n",
                "    torch.backends.cudnn.deterministic = True\n",
                "    torch.backends.cudnn.benchmark = False\n",
                "    \n",
                "    print(f\"Random seed set to {seed}\")\n",
                "\n",
                "set_seed(SEED)\n",
                "\n",
                "# Check for GPU\n",
                "if torch.cuda.is_available():\n",
                "    print(f\"\\nUsing GPU: {torch.cuda.get_device_name(0)}\")\n",
                "else:\n",
                "    print(\"\\nWARNING: GPU not available. Training will be slow.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1.3 Weights & Biases Setup"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "wandb.login(key=userdata.get('wandb'))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Model Initialization & Training"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Chronos-2 Forecasting Config\n",
                "chronos_forecasting_config = Chronos2ForecastingConfig(\n",
                "    context_length=CONTEXT_LENGTH,\n",
                "    output_patch_size=PATCH_SIZE,\n",
                "    input_patch_size=PATCH_SIZE,\n",
                "    input_patch_stride=PATCH_SIZE,\n",
                "    quantiles=QUANTILES,\n",
                "    time_encoding_scale=CONTEXT_LENGTH,\n",
                "    use_reg_token=True,\n",
                ")\n",
                "\n",
                "# Chronos-2 Core Config (Tiny ~15M)\n",
                "model_config = Chronos2CoreConfig(\n",
                "    d_model=D_MODEL,\n",
                "    d_kv=D_KV,\n",
                "    d_ff=D_FF,\n",
                "    num_layers=NUM_LAYERS,\n",
                "    num_heads=NUM_HEADS,\n",
                "    dropout_rate=DROPOUT_RATE,\n",
                "    vocab_size=VOCAB_SIZE,\n",
                ")\n",
                "model_config.chronos_config = chronos_forecasting_config.__dict__\n",
                "\n",
                "# Initialize Model\n",
                "model = Chronos2Model(model_config)\n",
                "print(f\"Model Parameters: {model.num_parameters() / 1e6:.2f}M\")\n",
                "\n",
                "# Prepare Datasets\n",
                "train_ds = Chronos2Dataset(\n",
                "    inputs=train_data,\n",
                "    context_length=CONTEXT_LENGTH,\n",
                "    prediction_length=PREDICTION_LENGTH,\n",
                "    batch_size=BATCH_SIZE,\n",
                "    output_patch_size=PATCH_SIZE,\n",
                "    mode=DatasetMode.TRAIN,\n",
                ")\n",
                "\n",
                "val_ds = Chronos2Dataset(\n",
                "    inputs=val_data,\n",
                "    context_length=CONTEXT_LENGTH,\n",
                "    prediction_length=PREDICTION_LENGTH,\n",
                "    batch_size=BATCH_SIZE,\n",
                "    output_patch_size=PATCH_SIZE,\n",
                "    mode=DatasetMode.VALIDATION,\n",
                ")\n",
                "\n",
                "# Training Arguments\n",
                "training_args = TrainingArguments(\n",
                "    output_dir=CHECKPOINT_DIR,\n",
                "    per_device_train_batch_size=BATCH_SIZE,\n",
                "    per_device_eval_batch_size=BATCH_SIZE,\n",
                "    learning_rate=LEARNING_RATE,\n",
                "    lr_scheduler_type=\"linear\",\n",
                "    warmup_ratio=WARMUP_RATIO,\n",
                "    max_steps=MAX_STEPS,\n",
                "    save_steps=SAVE_STEPS,\n",
                "    logging_steps=LOGGING_STEPS,\n",
                "    save_strategy=\"steps\",\n",
                "    fp16=False,\n",
                "    dataloader_num_workers=2,\n",
                "    remove_unused_columns=False,\n",
                "    report_to=\"wandb\",\n",
                "    run_name=RUN_NAME,\n",
                "    seed=SEED,\n",
                "    data_seed=SEED,\n",
                ")\n",
                "\n",
                "# Trainer\n",
                "trainer = Chronos2Trainer(\n",
                "    model=model,\n",
                "    args=training_args,\n",
                "    train_dataset=train_ds,\n",
                "    eval_dataset=val_ds,\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Run Training"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"Starting training...\")\n",
                "trainer.train()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Validation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"Running final validation...\")\n",
                "eval_results = trainer.evaluate()\n",
                "print(f\"Final Validation Results: {eval_results}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Benchmarking\n",
                "\n",
                "We evaluate the trained model on Monash benchmark datasets."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Define datasets to benchmark\n",
                "benchmark_datasets = [\n",
                "    {'name': 'electricity', 'prediction_length': 24, 'max_samples': 50},\n",
                "    {'name': 'traffic', 'prediction_length': 24, 'max_samples': 50},\n",
                "    {'name': 'm4_hourly', 'prediction_length': 48, 'max_samples': 50},\n",
                "]\n",
                "\n",
                "print(\"\\n\" + \"=\"*60)\n",
                "print(\"RUNNING BENCHMARKS\")\n",
                "print(\"=\"*60)\n",
                "print(f\"Total datasets: {len(benchmark_datasets)}\")\n",
                "\n",
                "# Run benchmark\n",
                "results_df = run_benchmark(\n",
                "    model=model,\n",
                "    datasets=benchmark_datasets,\n",
                "    batch_size=32,\n",
                ")\n",
                "\n",
                "# Display results\n",
                "if not results_df.empty:\n",
                "    cols = ['dataset', 'MASE', 'MAE', 'RMSE', 'wQuantileLoss[0.5]', 'wQuantileLoss[0.9]', 'CRPS']\n",
                "    cols = [c for c in cols if c in results_df.columns]\n",
                "    \n",
                "    print(\"\\n\" + \"=\"*60)\n",
                "    print(\"BENCHMARK RESULTS\")\n",
                "    print(\"=\"*60)\n",
                "    print(results_df[cols].to_string(index=False))\n",
                "    \n",
                "    # Log to WandB\n",
                "    print(\"\\n\" + \"=\"*60)\n",
                "    print(\"LOGGING TO WANDB\")\n",
                "    print(\"=\"*60)\n",
                "    \n",
                "    # Log individual dataset results\n",
                "    for _, row in results_df.iterrows():\n",
                "        dataset_name = row['dataset']\n",
                "        \n",
                "        # Create metrics dict\n",
                "        metrics = {}\n",
                "        for col in results_df.columns:\n",
                "            if col != 'dataset':\n",
                "                metrics[f\"benchmark/{dataset_name}/{col}\"] = row[col]\n",
                "        \n",
                "        wandb.log(metrics)\n",
                "    \n",
                "    # Log summary statistics\n",
                "    for metric in ['MASE', 'MAE', 'RMSE']:\n",
                "        if metric in results_df.columns:\n",
                "            wandb.log({f\"benchmark_summary/{metric}_mean\": results_df[metric].mean()})\n",
                "    \n",
                "    # Create and log a WandB table\n",
                "    wandb.log({\"benchmark_results\": wandb.Table(dataframe=results_df)})\n",
                "    \n",
                "    print(\"✓ Benchmark results logged to WandB\")\n",
                "    \n",
                "    # Save to CSV\n",
                "    results_df.to_csv('benchmark_results.csv', index=False)\n",
                "    print(\"\\n✓ Results saved to benchmark_results.csv\")\n",
                "else:\n",
                "    print(\"No benchmark results generated.\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
