{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 00. Data Setup\n",
                "\n",
                "This notebook generates the synthetic training data for Chronos-2 and saves it to disk. This ensures that the training process uses a fixed, reproducible dataset."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "208a4836",
            "metadata": {},
            "outputs": [],
            "source": [
                "!git clone https://github.com/emanueleromito/voyagers-forecasting.git\n",
                "%cd voyagers-forecasting\n",
                "\n",
                "# Install package\n",
                "!pip install -e .\n",
                "!pip install huggingface_hub"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "e0624b44",
            "metadata": {},
            "outputs": [],
            "source": [
                "from google.colab import userdata\n",
                "import sys\n",
                "import os\n",
                "import torch\n",
                "import numpy as np\n",
                "from huggingface_hub import login, HfApi\n",
                "from tqdm.auto import tqdm\n",
                "\n",
                "# Add src to path\n",
                "sys.path.append(os.path.abspath(\"src\"))\n",
                "\n",
                "from chronos2.data.generation.univariate import (\n",
                "    KernelSynthGenerator,\n",
                "    ARGenerator,\n",
                "    TrendSeasonalityGenerator,\n",
                ")\n",
                "from chronos2.data.generation.tasks import TaskSampler"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "75dc3761",
            "metadata": {},
            "source": [
                "## Configuration"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "1bf3d16e",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Hugging Face Hub Configuration\n",
                "HF_REPO_ID = \"voyagersnlppolito/model-data\"\n",
                "HF_TOKEN = userdata.get('HF_TOKEN')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Initialize Generators"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "base_generators = [\n",
                "    KernelSynthGenerator(),\n",
                "    ARGenerator(order=1),\n",
                "    ARGenerator(order=2),\n",
                "    TrendSeasonalityGenerator(),\n",
                "]\n",
                "\n",
                "task_sampler = TaskSampler(\n",
                "    base_generators=base_generators,\n",
                "    univariate_prob=0.4,\n",
                "    multivariate_prob=0.3,\n",
                "    covariate_prob=0.3,\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Generate Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(f\"Generating {NUM_SAMPLES} synthetic tasks...\")\n",
                "dataset = []\n",
                "\n",
                "for i in tqdm(range(NUM_SAMPLES)):\n",
                "    # Use a deterministic seed for each sample\n",
                "    task = task_sampler.sample(length=DATA_LENGTH, random_state=SEED + i)\n",
                "    dataset.append(task)\n",
                "\n",
                "print(\"Generation complete.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Save Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(f\"Saving dataset to {OUTPUT_PATH}...\")\n",
                "torch.save(dataset, OUTPUT_PATH)\n",
                "print(\"Done.\")\n",
                "\n",
                "# Upload to Hugging Face Hub\n",
                "print(f\"Uploading to {HF_REPO_ID}...\")\n",
                "if HF_TOKEN:\n",
                "    login(token=HF_TOKEN)\n",
                "\n",
                "api = HfApi()\n",
                "api.create_repo(repo_id=HF_REPO_ID, exist_ok=True, repo_type=\"dataset\")\n",
                "api.upload_file(\n",
                "    path_or_fileobj=OUTPUT_PATH,\n",
                "    path_in_repo=\"synthetic_dataset.pt\",\n",
                "    repo_id=HF_REPO_ID,\n",
                "    repo_type=\"dataset\"\n",
                ")\n",
                "print(\"Upload complete.\")\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
