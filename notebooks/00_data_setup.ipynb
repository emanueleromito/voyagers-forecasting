{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 00. Data Setup\n",
                "\n",
                "This notebook generates the synthetic training data for Chronos-2 and saves it to disk. This ensures that the training process uses a fixed, reproducible dataset."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "208a4836",
            "metadata": {},
            "outputs": [],
            "source": [
                "!git clone https://github.com/emanueleromito/voyagers-forecasting.git\n",
                "%cd voyagers-forecasting\n",
                "\n",
                "# Install package\n",
                "!pip install -e .\n",
                "!pip install huggingface_hub gluonts scikit-learn"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "e0624b44",
            "metadata": {},
            "outputs": [],
            "source": [
                "from google.colab import userdata\n",
                "import sys\n",
                "import os\n",
                "import torch\n",
                "import numpy as np\n",
                "from joblib import Parallel, delayed\n",
                "import functools\n",
                "from typing import Optional\n",
                "from pathlib import Path\n",
                "from huggingface_hub import login, HfApi\n",
                "from tqdm.auto import tqdm\n",
                "from gluonts.dataset.arrow import ArrowWriter\n",
                "from sklearn.gaussian_process import GaussianProcessRegressor\n",
                "from sklearn.gaussian_process.kernels import (\n",
                "    RBF,\n",
                "    ConstantKernel,\n",
                "    DotProduct,\n",
                "    ExpSineSquared,\n",
                "    Kernel,\n",
                "    RationalQuadratic,\n",
                "    WhiteKernel,\n",
                ")\n",
                "\n",
                "# Add src to path\n",
                "sys.path.append(os.path.abspath(\"src\"))"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "75dc3761",
            "metadata": {},
            "source": [
                "## Configuration"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "1bf3d16e",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Data Generation Configuration\n",
                "SEED = 42\n",
                "NUM_SAMPLES = 1000  # Reduced for demo purposes, increase for real training\n",
                "DATA_LENGTH = 1024   # Length of each time series\n",
                "OUTPUT_PATH = \"synthetic_dataset.arrow\"\n",
                "MAX_KERNELS = 5\n",
                "\n",
                "# Hugging Face Hub Configuration\n",
                "HF_REPO_ID = \"voyagersnlppolito/model-data\"\n",
                "HF_TOKEN = userdata.get('HF_TOKEN')"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "da7f3225",
            "metadata": {},
            "source": [
                "## KernelSynth Logic\n",
                "\n",
                "The following code implements the KernelSynth logic for generating synthetic time series using Gaussian Processes with random kernels."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "kernelsynth-logic",
            "metadata": {},
            "outputs": [],
            "source": [
                "LENGTH = DATA_LENGTH\n",
                "KERNEL_BANK = [\n",
                "    ExpSineSquared(periodicity=24 / LENGTH),  # H\n",
                "    ExpSineSquared(periodicity=48 / LENGTH),  # 0.5H\n",
                "    ExpSineSquared(periodicity=96 / LENGTH),  # 0.25H\n",
                "    ExpSineSquared(periodicity=24 * 7 / LENGTH),  # H\n",
                "    ExpSineSquared(periodicity=48 * 7 / LENGTH),  # 0.5H\n",
                "    ExpSineSquared(periodicity=96 * 7 / LENGTH),  # 0.25H\n",
                "    ExpSineSquared(periodicity=7 / LENGTH),  # D\n",
                "    ExpSineSquared(periodicity=14 / LENGTH),  # 0.5D\n",
                "    ExpSineSquared(periodicity=30 / LENGTH),  # D\n",
                "    ExpSineSquared(periodicity=60 / LENGTH),  # 0.5D\n",
                "    ExpSineSquared(periodicity=365 / LENGTH),  # D\n",
                "    ExpSineSquared(periodicity=365 * 2 / LENGTH),  # 0.5D\n",
                "    ExpSineSquared(periodicity=4 / LENGTH),  # W\n",
                "    ExpSineSquared(periodicity=26 / LENGTH),  # W\n",
                "    ExpSineSquared(periodicity=52 / LENGTH),  # W\n",
                "    ExpSineSquared(periodicity=4 / LENGTH),  # M\n",
                "    ExpSineSquared(periodicity=6 / LENGTH),  # M\n",
                "    ExpSineSquared(periodicity=12 / LENGTH),  # M\n",
                "    ExpSineSquared(periodicity=4 / LENGTH),  # Q\n",
                "    ExpSineSquared(periodicity=4 * 10 / LENGTH),  # Q\n",
                "    ExpSineSquared(periodicity=10 / LENGTH),  # Y\n",
                "    DotProduct(sigma_0=0.0),\n",
                "    DotProduct(sigma_0=1.0),\n",
                "    DotProduct(sigma_0=10.0),\n",
                "    RBF(length_scale=0.1),\n",
                "    RBF(length_scale=1.0),\n",
                "    RBF(length_scale=10.0),\n",
                "    RationalQuadratic(alpha=0.1),\n",
                "    RationalQuadratic(alpha=1.0),\n",
                "    RationalQuadratic(alpha=10.0),\n",
                "    WhiteKernel(noise_level=0.1),\n",
                "    WhiteKernel(noise_level=1.0),\n",
                "    ConstantKernel(),\n",
                "]\n",
                "\n",
                "def random_binary_map(a: Kernel, b: Kernel):\n",
                "    \"\"\"\n",
                "    Applies a random binary operator (+ or *) with equal probability\n",
                "    on kernels ``a`` and ``b``.\n",
                "    \"\"\"\n",
                "    binary_maps = [lambda x, y: x + y, lambda x, y: x * y]\n",
                "    return np.random.choice(binary_maps)(a, b)\n",
                "\n",
                "def sample_from_gp_prior(\n",
                "    kernel: Kernel, X: np.ndarray, random_seed: Optional[int] = None\n",
                "):\n",
                "    \"\"\"\n",
                "    Draw a sample from a GP prior.\n",
                "    \"\"\"\n",
                "    if X.ndim == 1:\n",
                "        X = X[:, None]\n",
                "\n",
                "    assert X.ndim == 2\n",
                "    gpr = GaussianProcessRegressor(kernel=kernel)\n",
                "    ts = gpr.sample_y(X, n_samples=1, random_state=random_seed)\n",
                "\n",
                "    return ts\n",
                "\n",
                "def generate_time_series(max_kernels: int = 5, seed: int = None):\n",
                "    \"\"\"Generate a synthetic time series from KernelSynth.\"\"\"\n",
                "    if seed is not None:\n",
                "        np.random.seed(seed)\n",
                "        \n",
                "    while True:\n",
                "        X = np.linspace(0, 1, LENGTH)\n",
                "\n",
                "        # Randomly select upto max_kernels kernels from the KERNEL_BANK\n",
                "        selected_kernels = np.random.choice(\n",
                "            KERNEL_BANK, np.random.randint(1, max_kernels + 1), replace=True\n",
                "        )\n",
                "\n",
                "        # Combine the sampled kernels using random binary operators\n",
                "        kernel = functools.reduce(random_binary_map, selected_kernels)\n",
                "\n",
                "        # Sample a time series from the GP prior\n",
                "        try:\n",
                "            ts = sample_from_gp_prior(kernel=kernel, X=X, random_seed=seed)\n",
                "        except np.linalg.LinAlgError as err:\n",
                "            # print(\"Error caught:\", err)\n",
                "            continue\n",
                "\n",
                "        # The timestamp is arbitrary\n",
                "        return {\"start\": np.datetime64(\"2000-01-01 00:00\", \"s\"), \"target\": ts.squeeze()}"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Generate Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(f\"Generating {NUM_SAMPLES} synthetic tasks...\")\n",
                "dataset = []\n",
                "\n",
                "# Parallel generation using joblib\n",
                "dataset = Parallel(n_jobs=-1)(\n",
                "    delayed(generate_time_series)(max_kernels=MAX_KERNELS, seed=SEED + i)\n",
                "    for i in tqdm(range(NUM_SAMPLES))\n",
                ")\n",
                "\n",
                "print(\"Generation complete.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Save Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(f\"Saving dataset to {OUTPUT_PATH}...\")\n",
                "ArrowWriter(compression=\"lz4\").write_to_file(\n",
                "    dataset,\n",
                "    path=Path(OUTPUT_PATH),\n",
                ")\n",
                "print(\"Done.\")\n",
                "\n",
                "# Upload to Hugging Face Hub\n",
                "print(f\"Uploading to {HF_REPO_ID}...\")\n",
                "if HF_TOKEN:\n",
                "    login(token=HF_TOKEN)\n",
                "\n",
                "api = HfApi()\n",
                "api.create_repo(repo_id=HF_REPO_ID, exist_ok=True, repo_type=\"dataset\")\n",
                "api.upload_file(\n",
                "    path_or_fileobj=OUTPUT_PATH,\n",
                "    path_in_repo=\"synthetic_dataset.arrow\",\n",
                "    repo_id=HF_REPO_ID,\n",
                "    repo_type=\"dataset\"\n",
                ")\n",
                "print(\"Upload complete.\")\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}